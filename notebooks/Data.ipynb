{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import utils\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dataloader.data import MIMICDataset, get_tables, JointTabularFeature\n",
    "from dataloader.labels import get_labels\n",
    "from dataloader.utils import BinnedEvent, get_vocab\n",
    "from utils import prepare_batch, load_class, load_model, load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cpu'\n",
    "data_path = 'data/multitask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = load_config('2xdwyub7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_vocab = get_vocab(**params)\n",
    "tables = get_tables(load=True,\n",
    "                    event_class=BinnedEvent,\n",
    "                    vocab=joint_vocab,\n",
    "                    **params)\n",
    "\n",
    "labels = get_labels(DEVICE)\n",
    "\n",
    "train_set = MIMICDataset(datalist_file='train_listfile.csv', mode='EVAL',\n",
    "                         tables=tables, labels=labels,\n",
    "                         limit=2000,\n",
    "                         numericalize=True,\n",
    "                         )\n",
    "\n",
    "val_set = MIMICDataset(datalist_file='val_listfile.csv', mode='EVAL',\n",
    "                       tables=tables, labels=labels,\n",
    "                       limit=None,\n",
    "                       numericalize=True,\n",
    "                       )\n",
    "\n",
    "test_set = MIMICDataset(datalist_file='test_listfile.csv', mode='EVAL',\n",
    "                        datasplit='test',\n",
    "                        tables=tables, labels=labels,\n",
    "                        limit=None,\n",
    "                        numericalize=True,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[1].tables[0].value_counter['Heart-Rhythm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables[2].counts['FARR-10-OUTPUT-TOTAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[key for key in tables[2].bins.keys() if 'biliary' in key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tables = tables[1].tables\n",
    "j = 0 \n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 5))\n",
    "for i, t in enumerate(tables):\n",
    "    values = list(t.bins.items())\n",
    "    axes[i][0].set_ylabel(f'{t.table}')\n",
    "    while True:\n",
    "        ind = np.random.choice(len(t.bins))\n",
    "        key = values[ind][0]\n",
    "        if sum(t.counts[key]) < 10: continue\n",
    "        _bins = t.bins[key][:-1]\n",
    "        axes[i][j].bar(range(7), t.counts[key])\n",
    "        axes[i][j].set_title(f'{values[ind][0]:.20s}')\n",
    "        axes[i][j].tick_params(axis='y', labelrotation=45)\n",
    "        axes[i][j].set_xticks(range(0, 7))\n",
    "        axes[i][j].set_xticklabels([f'#{b}' for b in range(1, 8)])\n",
    "        j += 1\n",
    "        if j == 3:\n",
    "            j = 0\n",
    "            break\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/histograms.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.datalist_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "demog = pd.read_csv('mimic3-benchmarks/data/multitask/train/demogfile.csv').set_index('filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = utils.load_model(params, joint_vocab, tables, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=params['batch_size'],\n",
    "                                           collate_fn=partial(utils.min_batch,\n",
    "                                                              tables=tables,\n",
    "                                                              labels=labels,\n",
    "                                                              limit=720),\n",
    "                                           shuffle=False, num_workers=0, pin_memory=True, drop_last=True,\n",
    "                                          )\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=params['batch_size'],\n",
    "                                         collate_fn=partial(utils.min_batch,\n",
    "                                                            tables=tables,\n",
    "                                                            labels=labels,\n",
    "                                                            limit=None),\n",
    "                                         shuffle=False, num_workers=0, pin_memory=True, drop_last=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=params['batch_size'],\n",
    "                                         collate_fn=partial(utils.min_batch,\n",
    "                                                            tables=tables,\n",
    "                                                            labels=labels,\n",
    "                                                            limit=None),\n",
    "                                         shuffle=False, num_workers=0, pin_memory=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_event_counts(loader):\n",
    "    SUMMARY = defaultdict(dict)\n",
    "\n",
    "    for sample in loader:\n",
    "        x, y, extra = prepare_batch(sample, DEVICE)\n",
    "        for table in [t for t in tables if t.table != 'dem']:\n",
    "            events_per_step = (x[table.table][0,:,:,0] != 0).sum(1).tolist()\n",
    "            for step in range(len(events_per_step)):\n",
    "                SUMMARY[table.table, extra['filename'][0], step] = events_per_step[step]\n",
    "\n",
    "    mux = pd.MultiIndex.from_tuples(SUMMARY.keys())\n",
    "    df = pd.DataFrame(list(SUMMARY.values()), index=mux)\n",
    "    df = df.unstack(0)\n",
    "    df.columns = df.columns.get_level_values(1)\n",
    "    df = df.reset_index(1)\n",
    "    df['period_length'] = df['level_1']\n",
    "    df = df.drop('level_1', 1)\n",
    "    df = df.reset_index()\n",
    "    df['stay'] = df['index']\n",
    "    df = df.drop('index', 1)\n",
    "    df = df.loc[: , ['stay', 'period_length', 'CHARTEVENTS', 'LABEVENTS', 'OUTPUTEVENTS', 'INPUTEVENTS_*', 'PRESCRIPTIONS']]\n",
    "\n",
    "    df.to_csv(f'notebooks/{loader.dataset.datalist_filename}_n_events.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_event_counts(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_event_counts(train_loader)\n",
    "write_event_counts(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(CHART_SUMMARY['lengths'])[:,0], bins=20)\n",
    "plt.title(f'#TIMESTEPS min_word_count={params[\"min_word_count\"]}, batch_size={params[\"batch_size\"]}')\n",
    "plt.savefig(f'TIMESTEPS_min_word_count-{params[\"min_word_count\"]}_batch_size-{params[\"batch_size\"]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.array(CHART_SUMMARY['lengths'])[:,1], bins=20)\n",
    "plt.title(f'#EVENTS min_word_count={params[\"min_word_count\"]}, batch_size={params[\"batch_size\"]}')\n",
    "plt.savefig(f'EVENTS_min_word_count-{params[\"min_word_count\"]}_batch_size-{params[\"batch_size\"]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(sum(CHART_SUMMARY['event_lengths'], []), bins=20)\n",
    "plt.title(f'CHART: #TIMESTEPLENGTHS min_word_count={params[\"min_word_count\"]}, batch_size={params[\"batch_size\"]}')\n",
    "plt.savefig(f'CHART_TIMESTEPLENGTHS_min_word_count-{params[\"min_word_count\"]}_batch_size-{params[\"batch_size\"]}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "filenames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_loader:\n",
    "    x, y_true, extra = prepare_batch(batch, DEVICE)\n",
    "\n",
    "    preds, outputs = model(*x)\n",
    "    output = {\"y_pred\": preds,\n",
    "              \"y_true\": y_true}\n",
    "    \n",
    "    embeddings.append(outputs['patient'][0][-1].detach().numpy())\n",
    "    filenames.append(extra['filename'])\n",
    "    losses = {}\n",
    "    for label in labels.values():\n",
    "        losses[label.task] = label.loss(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['timesteps'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(outputs['timesteps'][0][0].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N_EVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = ['CHARTEVENTS', 'LABEVENTS', 'OUTPUTEVENTS', 'INPUTEVENTS_*', 'PRESCRIPTIONS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = pd.read_csv('./notebooks/train_listfile_n_events.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events['TOTAL'] = n_events[tables].sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_n_events = n_events.groupby('stay').agg(['count', 'max', 'median', 'mean', 'sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_n_events[[(t, 'sum') for t in tables]].sum(1).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_n_events[('period_length', 'count')].hist(bins=36, grid=False, range=(0, 864))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_n_events.TOTAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.get_yaxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(7, 2.7), dpi=300, sharey=True)\n",
    "\n",
    "axes[0].set_title('Length of stay')\n",
    "agg_n_events[('period_length', 'count')].hist(bins=36, grid='y', range=(0, 29 * 24), ax=axes[0])\n",
    "axes[0].set_xlabel('Days')\n",
    "axes[0].set_xticks(range(0, 29 * 24, 24 * 7))\n",
    "axes[0].set_xticklabels(range(0, 35, 7))\n",
    "axes[0].set_ylabel('Number of ICU stays')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "agg_n_events[[(t, 'sum') for t in tables]].sum(1).hist(bins=30, range=(0, 30000), grid='y', ax=axes[1])\n",
    "axes[1].set_title('#Events per stay')\n",
    "axes[1].xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "axes[1].set_xlabel('Events')\n",
    "axes[1].set_yscale('log')\n",
    "\n",
    "agg_n_events[('TOTAL', 'median')].hist(bins=30, range=(0, 200), grid='y', ax=axes[2])\n",
    "axes[2].set_title('Median of events per hour')\n",
    "axes[2].set_xlabel('Median of events/h')\n",
    "axes[2].xaxis.set_major_locator(plt.MaxNLocator(4))\n",
    "axes[2].set_yscale('log')\n",
    "\n",
    "plt.tight_layout(pad=0.2)\n",
    "plt.savefig('notebooks/figures/timesteps-events.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((pd.read_csv('./notebooks/train_listfile_n_events.csv').groupby('stay').max()))['period_length'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('mimic3-benchmarks/data/multitask/train_listfile.csv')['length of stay'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event types per table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables[1:]:\n",
    "    print(table.table)\n",
    "    all_values = {}\n",
    "    for event_label, values in table.value_counter.items():\n",
    "        for value_label, count in values.items():\n",
    "            if count < 10:\n",
    "                continue\n",
    "            if value_label == 'scalar':\n",
    "                for bin_ in range(len(table.counts[event_label])):\n",
    "                    all_values[event_label+'='+str(bin_)] = int(table.counts[event_label][bin_])\n",
    "            else:\n",
    "                all_values[event_label+'='+value_label] = count\n",
    "    print(len(all_values))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(len(table.counts[event_label])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table in tables[1:]:\n",
    "    print(table.table)\n",
    "    events = sorted([(event_label + '=' + value, count) for event_label, v in table.value_counter.items() for value, count in v.items() if count > 10], key=lambda x: x[1], reverse=True)\n",
    "    print(len(events))\n",
    "    print(len(table.value_counter))\n",
    "    dist_events = set([event_label for event_label, v in table.value_counter.items() for value, count in v.items() if count > 10])\n",
    "    print(len(dist_events))\n",
    "    print(events[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.numericalize = True\n",
    "train_set[292]['inputs']['OUTPUTEVENTS'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_vocab.freqs['Jackson-Pratt-#1=3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.numericalize = True\n",
    "for i in train_set[292]['inputs']['OUTPUTEVENTS'][2][:, 0].tolist():\n",
    "    print(i, joint_vocab.itos[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.numericalize = False\n",
    "train_set[292]['inputs']['OUTPUTEVENTS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dist_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11594 + 1082 + 290 + 1339 + 863"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tables[1].value_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_labels = ['Respiratory-Rate', 'Heart-Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['strategy'] = 'uniform'\n",
    "uniform_table = get_tables(load=True,\n",
    "                    event_class=BinnedEvent,\n",
    "                    vocab=joint_vocab,\n",
    "                    **params)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['strategy'] = 'kmeans'\n",
    "kmeans_table = get_tables(load=True,\n",
    "                    event_class=BinnedEvent,\n",
    "                    vocab=joint_vocab,\n",
    "                    **params)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"darkgrid\")\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "\n",
    "fig = plt.figure(figsize=(5.6, 3), dpi=300)\n",
    "\n",
    "event_labels = ['Respiratory-Rate', 'Glucose', 'Xigris']\n",
    "for i, event_label in enumerate(event_labels, 1):\n",
    "    ax = plt.subplot(1, len(event_labels), i)\n",
    "    \n",
    "    _bins = kmeans_table.bins[event_label]\n",
    "    _counts = -np.array(kmeans_table.counts[event_label])\n",
    "    ax.barh(_bins[:-1], _counts, np.diff(_bins), align='edge', label='k-means')#, alpha=0.5)    \n",
    "    _bins = uniform_table.bins[event_label]\n",
    "    _counts = np.array(uniform_table.counts[event_label])\n",
    "    ax.barh(_bins[:-1], _counts, np.diff(_bins), align='edge', label='uniform')#, alpha=0.5)\n",
    "    \n",
    "    if i == 1:\n",
    "        ax.set_ylabel('Observed value')\n",
    "    if i == 2:\n",
    "        ax.set_xlabel('Number of occurance')\n",
    "    ax.set_title(f'{event_label}')\n",
    "    ax.set_ymargin(0)\n",
    "\n",
    "    xabs_max = abs(max(ax.get_xlim(), key=abs))\n",
    "    ax.set_xlim(-xabs_max, xabs_max)\n",
    "\n",
    "    ax.xaxis.set_major_locator(plt.MaxNLocator(1))\n",
    "    ax.xaxis.set_major_formatter(ScalarFormatter())\n",
    "    ax.get_xaxis().get_offset_text().set_visible(False)\n",
    "    ax.ticklabel_format(axis='x', style='sci', useMathText=True, scilimits=(-3,3))\n",
    "    if i < 3:\n",
    "        ax_max = max(ax.get_xticks())\n",
    "        exponent_axis = np.floor(np.log10(ax_max)).astype(int)\n",
    "        ax.set_xticklabels([f'${c//(10**(exponent_axis-1))}\\\\times10^{exponent_axis-1}$' if c != 0 else '0' for c in np.abs(ax.get_xticks()).round(0).astype(int)])\n",
    "    else:\n",
    "        ax.set_xticklabels(np.abs(ax.get_xticks()).round(0).astype(int))\n",
    "    xabs_max = abs(max(ax.get_xlim(), key=abs))\n",
    "    ax.set_xlim(-xabs_max, xabs_max)\n",
    "    \n",
    "\n",
    "plt.tight_layout(pad=0, h_pad=0)\n",
    "plt.savefig('notebooks/figures/discritization.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exponent_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = ax.get_xticklabels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time input\n",
    "plt.title('Time Input')\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(np.arange(720), np.log(np.arange(720)+1), label='$\\log(h+1)$')\n",
    "ax.plot(np.arange(720), np.exp(np.arange(720)/1000)-1, label='$\\exp(h)/1000+1$')\n",
    "ax.set_xlabel('Hours ($h$)')\n",
    "ax.set_ylabel('Time Feature ($F_h$)')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hours = []\n",
    "n_measures = {\n",
    "    'CHARTEVENTS': [],\n",
    "    'LABEVENTS': [],\n",
    "    'OUTPUTEVENTS': [],\n",
    "    'INPUTEVENTS_*': [],\n",
    "    'PRESCRIPTIONS': []\n",
    "}\n",
    "for patient in train_set:\n",
    "    n_hours.append(len(patient['inputs']['CHARTEVENTS']))\n",
    "    for table in n_measures.keys():\n",
    "        n_measures[table].append((patient['extra']['filename'], [len(hour) for hour in patient['inputs'][table]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(n_hours), np.median(n_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tabl, patients in n_measures.items():\n",
    "    print('mean number of measures in', tabl, np.mean([np.mean([hour for hour in hours if hour > 0]) for hours in patients if [hour for hour in hours if hour > 0]]))\n",
    "    print('rate of eventful hours', tabl, np.mean([np.mean(np.array(hours)>0) for hours in patients]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.array(patients[0]) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(n_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.utils import feature_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mimic3-benchmarks/mimic3benchmark/resources/itemid_to_variable_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.STATUS == 'ready']['MIMIC LABEL']\\\n",
    "    .apply(feature_string).apply(lambda x: '^' + x + '(_?.*?)?\\s')\\\n",
    "    .to_csv('embeddings/benchmark_features_greppatterns3', index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/oserbetci/EffiCare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = pd.read_csv('embeddings/sentences.mimic3.txt.100d.Fasttext.15ws.onlybenchmark.vec', sep=' ', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import samplers\n",
    "sampler = samplers.DiagnoseAgeSubjectRandomSampler(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in sampler:\n",
    "    print(sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sampler.sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icu",
   "language": "python",
   "name": "icu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import torch\n",
    "import gzip\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "import yaml\n",
    "from glob import glob\n",
    "from functools import partial\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from dataloader.data import MIMICDataset, get_tables\n",
    "from dataloader.labels import get_labels\n",
    "from dataloader.utils import BinnedEvent, get_vocab\n",
    "from utils import prepare_batch, load_class, load_model, load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oserbetci/ICU-RL/utils.py:385: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  c = yaml.load(f)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('models.PatientChannelRNNMaxPoolEncoder', 'models.MultitaskFinetune')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda:0'\n",
    "RUN_ID = '2xdwyub7'\n",
    "LISTFILE_ROOT = '/home/ashankar/mimic3_data/data/'\n",
    "LISTFILE = 'test_listfile'\n",
    "THRES = 0.92\n",
    "\n",
    "params = load_config(RUN_ID)\n",
    "# params['vocab_file'] = 'embeddings/sentences.mimic3.hourly.random.binned.train.counts'\n",
    "params['patient_modelcls'], params['modelcls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "joint_vocab = get_vocab(**params)\n",
    "\n",
    "tables = get_tables(load=True,\n",
    "                    event_class=BinnedEvent,\n",
    "                    vocab=joint_vocab,\n",
    "                    **params)\n",
    "\n",
    "labels = get_labels(DEVICE)\n",
    "\n",
    "train_set = MIMICDataset(datalist_file='train_listfile.csv', mode='EVAL',\n",
    "                         tables=tables, labels=labels,\n",
    "                         limit=None,\n",
    "                         numericalize=True)\n",
    "val_set = MIMICDataset(datalist_file='val_listfile.csv', mode='EVAL',\n",
    "                       tables=tables, labels=labels,\n",
    "                       limit=128,\n",
    "                       numericalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, \n",
    "                                           batch_size=params['batch_size'], \n",
    "                                           collate_fn=partial(utils.pad_batch,\n",
    "                                                              tables=tables,\n",
    "                                                              labels=labels,\n",
    "                                                              limit=48),\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0,\n",
    "                                           pin_memory=False,\n",
    "                                           drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_set,\n",
    "                                         batch_size=params['batch_size'], \n",
    "                                         collate_fn=partial(utils.pad_batch,\n",
    "                                                            tables=tables,\n",
    "                                                            labels=labels,\n",
    "                                                            limit=None),\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4,\n",
    "                                         pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(params, joint_vocab, tables, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Collect patient embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.timestep_encoder.event_encoder.encoder.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [00:10, 12.02it/s]\n"
     ]
    }
   ],
   "source": [
    "tok_acts = []\n",
    "pheno_labels = []\n",
    "ihm_labels = []\n",
    "los_labels = []\n",
    "decomp_labels = []\n",
    "pheno_preds = []\n",
    "decomp_preds = []\n",
    "ihm_preds = []\n",
    "los_preds = []\n",
    "patients = []\n",
    "\n",
    "for i, batch in tqdm(enumerate(val_loader)):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y_trues, extras = prepare_batch(batch, DEVICE)\n",
    "        # skip masked\n",
    "        if y_trues['in_hospital_mortality'][0,0] == 0.: continue\n",
    "        \n",
    "        y_preds, extra = model(*x.values())\n",
    "        patients.append(extra['patient'].detach().cpu().numpy())\n",
    "\n",
    "        pheno_labels.append(y_trues['phenotyping'].detach().cpu().numpy())\n",
    "        ihm_labels.append(y_trues['in_hospital_mortality'].detach().cpu().numpy())\n",
    "        los_labels.append(y_trues['length_of_stay_classification'].detach().cpu().numpy())\n",
    "        decomp_labels.append(y_trues['decompensation'].detach().cpu().numpy())\n",
    "        decomp_preds.append(y_trues['decompensation'].detach().cpu().numpy())\n",
    "        pheno_preds.append(y_preds['phenotyping'].detach().cpu().numpy())\n",
    "        ihm_preds.append(y_preds['in_hospital_mortality'].detach().cpu().numpy())\n",
    "        los_preds.append(y_preds['length_of_stay_classification'].detach().cpu().numpy())\n",
    "        \n",
    "        output = {}\n",
    "        output['y_pred'] = y_preds\n",
    "        output['y_true'] = y_trues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihm_labels = np.concatenate(ihm_labels, 0)\n",
    "los_labels = np.concatenate([l[:,1,47] for l in los_labels if l.shape[2] > 47], 0)\n",
    "decomp_labels = np.concatenate(decomp_labels, -1)\n",
    "decomp_preds = np.concatenate(decomp_preds, -1)\n",
    "ihm_preds = np.concatenate(ihm_preds, 0)\n",
    "los_preds = np.concatenate([l[:,47].argmax(-1) for l in los_preds if l.shape[1] > 47], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomp_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats = np.concatenate(patients, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihm = np.concatenate([p[:, 47] for p in patients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((decomp_labels[0, 0] == 1.) & ((decomp_labels[0, 1]) == (decomp_preds[0, 1] > 0.9973))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihm_pos = ihm[(ihm_labels[:, 0] == 1.) & ((ihm_labels[:, 1]) == (ihm_preds[:, 0] > .92))]\n",
    "decomp_pos = pats[(decomp_labels[0, 0] == 1.) & ((decomp_labels[0, 1]) == (decomp_preds[0, 1] > 0.9973))]\n",
    "los_pos = ihm[los_labels == los_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = np.mean(ihm_pos, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihm_acts = np.mean([p[0,47] for p in ihm_pos], 0)\n",
    "decomp_acts = np.mean([p[0, 4:].mean(0) for p in decomp_pos],0)\n",
    "los_pos = np.mean([p[0, 4:].mean(0) for p in los_pos],0)\n",
    "phen_acts = np.mean([p[0,-1] for p in patients],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ihm_acts.shape, decomp_acts.shape, phen_acts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_pos(x):\n",
    "    return x[x > 0.].sum()\n",
    "\n",
    "def sum_neg(x):\n",
    "    return x[x < 0.].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pooling = sum([[f'{i} over time, {j} over events']*50 for i in ['max-pool', 'avg-pool', 'sum-pool'] for j in ['max-pool', 'avg-pool', 'sum-pool']], [])\n",
    "table_dem = ['dem'] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_dist(acts, y_axis='Mean activation'):\n",
    "    dfs = []\n",
    "    for tabl, ind, l in zip(['CHARTEVENTS', 'LABEVENTS', 'OUTPUTEVENTS', 'PRESCRIPTIONS', 'INPUTEVENTS', 'dem'], [0, 450, 900, 1350, 1800, 1820], [450, 450, 450, 450, 450, 20]):\n",
    "    #     breakpoint()\n",
    "        df = pd.DataFrame(acts[ind:ind+l],\n",
    "                         columns=[y_axis])\n",
    "        df['Source'] = tabl\n",
    "        if tabl != 'dem':\n",
    "            df['time-pool'] = sum([[p]*150 for p in ['max', 'avg', 'sum']], [])\n",
    "            df['Event pooling'] = sum([[p]*50 for p in ['max', 'avg', 'sum']*3], [])\n",
    "            df_pos = df.groupby(['time-pool', 'Event pooling', 'Source'])[y_axis].agg(sum_pos)\n",
    "            df_pos = df_pos.reset_index()\n",
    "            df_pos['Event pooling'] = sum([[f'${p}^+$'] for p in ['max', 'avg', 'sum']*3], [])\n",
    "\n",
    "            df_neg = df.groupby(['time-pool', 'Event pooling', 'Source'])[y_axis].agg(sum_neg)\n",
    "            df_neg = df_neg.reset_index()\n",
    "            df_neg['Event pooling'] = sum([[f'${p}^-$'] for p in ['max', 'avg', 'sum']*3], [])\n",
    "        else:\n",
    "            df['time-pool'] = 'dem'\n",
    "            df_pos = df.groupby(['Source'])[y_axis].agg(sum_pos)\n",
    "            df_pos = df_pos.reset_index()\n",
    "            df_pos['time-pool'] = 'dem'\n",
    "            df_pos['Event pooling'] = 'dem'\n",
    "\n",
    "            df_neg = df.groupby(['Source'])[y_axis].agg(sum_neg)\n",
    "            df_neg = df_neg.reset_index()\n",
    "            df_neg['time-pool'] = 'dem'\n",
    "            df_neg['Event pooling'] = 'dem'\n",
    "            \n",
    "            \n",
    "\n",
    "        df = pd.concat([df_pos, df_neg], 0)\n",
    "        dfs.append(df)\n",
    "    \n",
    "    return pd.concat(dfs, 0, ignore_index=True)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_source_dist(df, y_axis='Mean activation'):\n",
    "    fig = px.bar(df, x='time-pool', y=y_axis, color='Event pooling', width=800, height=400, barmode='relative', facet_col='Source')\n",
    "\n",
    "#     fig = px.histogram(df, x='pooling', y=y_axis, color='pooling', width=1100, height=400,\n",
    "#                        histfunc='sum', \n",
    "#                        facet_col='table')\n",
    "#     fig.update_traces(nbinsx=450//bin_size,  overwrite=True)\n",
    "#     fig.update_traces(width=0.7,  overwrite=True)\n",
    "    fig.for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1]))\n",
    "    fig.layout.legend.orientation = 'h'\n",
    "    fig.layout.legend.yanchor = 'top'\n",
    "    fig.layout.legend.xanchor = 'center'\n",
    "    fig.layout.legend.x = 0.5\n",
    "    fig.layout.legend.y = -0.3\n",
    "    fig.update_yaxes(col=1, title_text=f'Mean contribution')\n",
    "    fig.update_yaxes(overwrite=True,\n",
    "                     matches=None,\n",
    "                     row=1, \n",
    "                     col=6)\n",
    "    \n",
    "    fig.update_xaxes(overwrite=True,\n",
    "                     matches=None)\n",
    "    fig.update_xaxes(overwrite=True,\n",
    "#                      ticklabels=['avg', 'max', 'max'],\n",
    "#                      range=[0, 3],\n",
    "                    nticks=3,\n",
    "                    dtick=1)\n",
    "    fig.update_xaxes(overwrite=True,\n",
    "    #                  tick0=75, dtick=75, \n",
    "                     showgrid=True,\n",
    "                     title_text='',\n",
    "                     showticklabels=True)\n",
    "    fig.update_xaxes(overwrite=True,\n",
    "                     showticklabels=False,\n",
    "                     row=1,\n",
    "                     col=6)\n",
    "    \n",
    "    fig.update_xaxes(col=3, title_text=f'Time pooling')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_source_dist(decomp_acts, 'Mean activation')\n",
    "df.to_csv('exp_act.csv')\n",
    "fig = plot_source_dist(df)\n",
    "fig.update_layout(title_text='Patient activation')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.predictor.decision_mlps['in_hospital_mortality'].weight.detach().cpu().numpy()[0]\n",
    "bias = model.predictor.decision_mlps['in_hospital_mortality'].bias.detach().cpu().numpy()[0]\n",
    "\n",
    "df = get_source_dist(ihm_acts * weights)\n",
    "df.to_csv('exp_ihm.csv')\n",
    "fig = plot_source_dist(df, 'Mean activation')\n",
    "fig.update_layout(title_text='In-Hospital Mortality')\n",
    "fig.update_layout(showlegend=True)\n",
    "fig.update_yaxes(range=[-5,5], overwrite=True)\n",
    "fig.write_image('notebooks/figures/ihm-legend.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.predictor.decision_mlps['in_hospital_mortality'].weight.detach().cpu().numpy()[0]\n",
    "df = get_source_dist(ihm_acts * weights)\n",
    "df.to_csv('exp_ihm.csv')\n",
    "fig = plot_source_dist(df, 'Mean activation')\n",
    "fig.update_layout(title_text='In-Hospital Mortality')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(range=[-5,5], overwrite=True)\n",
    "fig.write_image('notebooks/figures/ihm.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.predictor.decision_mlps['decompensation'].weight.detach().cpu().numpy()[0]\n",
    "bias = model.predictor.decision_mlps['decompensation'].bias.detach().cpu().numpy()[0]\n",
    "\n",
    "df = get_source_dist(decomp_acts * weights, 'Mean activation')\n",
    "# df.to_csv('exp_decomp.csv')\n",
    "fig = plot_source_dist(df, 'Mean activation')\n",
    "fig.update_layout(title_text='Decompensation')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(range=[-5,5], overwrite=True)\n",
    "fig.write_image('notebooks/figures/decomp.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model.predictor.decision_mlps['length_of_stay_regression'].weight.detach().cpu().numpy()[0]\n",
    "print(weights.shape)\n",
    "df = get_source_dist(decomp_acts * weights, 'Mean activation')\n",
    "df.to_csv('exp_los.csv')\n",
    "fig = plot_source_dist(df, 'Mean activation')\n",
    "fig.update_layout(title_text='Length-of-stay regression')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(range=[-5,5], overwrite=True)\n",
    "fig.write_image('notebooks/figures/los.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_index = 8\n",
    "weights = model.predictor.decision_mlps['phenotyping'].weight.detach().cpu().numpy()[p_index]# + model.decision_mlps.decompensation.bias.detach().cpu().numpy()[0]\n",
    "df = get_source_dist(decomp_acts * weights, 'Mean activation')\n",
    "fig = plot_source_dist(df, 'Mean activation')\n",
    "fig.update_layout(title_text=f'Phenotyping: {labels[\"phenotyping\"].classes[p_index]}')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(range=[-.11,.11], overwrite=True)\n",
    "fig.write_image('notebooks/figures/pheno8.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_index = 0\n",
    "weights = model.predictor.decision_mlps['phenotyping'].weight.detach().cpu().numpy()[p_index]# + model.decision_mlps.decompensation.bias.detach().cpu().numpy()[0]\n",
    "df = get_source_dist(decomp_acts * weights, 'Mean activation')\n",
    "fig = plot_source_dist(df, 'Mean activation')\n",
    "fig.update_layout(title_text=f'Phenotyping: {labels[\"phenotyping\"].classes[p_index]}')\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(range=[-.11,.11], overwrite=True)\n",
    "fig.write_image('notebooks/figures/pheno0.pdf')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save activated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "act_paths = glob(f\"wandb/run-*{RUN_ID}/insight*/*.tsv.gz\")\n",
    "act_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "dfs = []\n",
    "for path in act_paths:\n",
    "#     if 'output' not in path: continue\n",
    "#     print(path)\n",
    "    with gzip.open(path, 'rt') as f:\n",
    "        df = pd.read_csv(f, sep='\\t')\n",
    "        m = re.match('.*/(.*?[A-Z]+).*_activations.*', path)\n",
    "        df['table'] = m[1]\n",
    "        dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    prediction = glob(f'wandb/*{RUN_ID}/{LISTFILE}_predictions/in_hospital_mortality*.csv')[-1]\n",
    "    test_listfile = f'{LISTFILE_ROOT}/in-hospital-mortality/{LISTFILE}.csv'\n",
    "pred_df = pd.read_csv(args.prediction, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['token'].isin(['<pad>'])]\n",
    "df = df.merge(pred_df, on='stay', how='right')\n",
    "assert not df.y_true.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "df = df[(df.prediction > 0.95) == df.y_true]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df['feature'] = df['token'].apply(lambda x: x.split('_')[0] if '_' in x else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sorted_df = df[['dim', 'feature', 'token', 'activation', 'table']].groupby(['feature', 'token', 'dim', 'table']).agg(['mean', 'sum', 'count', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.min_rows = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "sorted_df = sorted_df.sort_values(('activation', 'sum'), ascending=False).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df[:25].set_index(['table', 'dim', 'token']).sort_index()#.loc['events']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df.token.isin(sorted_df.iloc[:10].token)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#px.box(filtered_df, y='activation', x='token', color='table', width=1000, height=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "tokens = sorted_df[(sorted_df[('activation', 'count')]>1) & (sorted_df[('activation', 'sum')]>1)].reset_index()['token'].unique()\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# from datasets.utils import feature_string\n",
    "# import pandas as pd\n",
    "\n",
    "# with open('our_features_train', 'wt') as f:\n",
    "#     for feature in tokens:\n",
    "#         f.write(feature_string(feature) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icu",
   "language": "python",
   "name": "icu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "name": "Plot.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
